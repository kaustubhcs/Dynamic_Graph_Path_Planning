log4j:ERROR setFile(null,true) call failed.
java.io.FileNotFoundException: /stderr (Permission denied)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:133)
	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294)
	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165)
	at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:223)
	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307)
	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172)
	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104)
	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842)
	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768)
	at org.apache.log4j.PropertyConfigurator.parseCatsAndRenderers(PropertyConfigurator.java:672)
	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:516)
	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:580)
	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:526)
	at org.apache.log4j.LogManager.<clinit>(LogManager.java:127)
	at org.apache.spark.internal.Logging$class.initializeLogging(Logging.scala:120)
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:108)
	at org.apache.spark.deploy.SparkSubmit.initializeLogIfNecessary(SparkSubmit.scala:71)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:79)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log4j:ERROR Either File or DatePattern options are not set for appender [DRFA-stderr].
log4j:ERROR setFile(null,true) call failed.
java.io.FileNotFoundException: /stdout (Permission denied)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:133)
	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294)
	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165)
	at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:223)
	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307)
	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172)
	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104)
	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842)
	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768)
	at org.apache.log4j.PropertyConfigurator.parseCatsAndRenderers(PropertyConfigurator.java:672)
	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:516)
	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:580)
	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:526)
	at org.apache.log4j.LogManager.<clinit>(LogManager.java:127)
	at org.apache.spark.internal.Logging$class.initializeLogging(Logging.scala:120)
	at org.apache.spark.internal.Logging$class.initializeLogIfNecessary(Logging.scala:108)
	at org.apache.spark.deploy.SparkSubmit.initializeLogIfNecessary(SparkSubmit.scala:71)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:79)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log4j:ERROR Either File or DatePattern options are not set for appender [DRFA-stdout].
19/04/20 03:34:39 WARN DependencyUtils: Skip remote jar s3://cs-6240-hemnaniv/DGPP-project/v3-all-pair-5-clusters-n-7/spark-dpp-1.0.jar.
19/04/20 03:34:39 INFO RMProxy: Connecting to ResourceManager at ip-172-31-51-240.ec2.internal/172.31.51.240:8032
19/04/20 03:34:40 INFO Client: Requesting a new application from cluster with 5 NodeManagers
19/04/20 03:34:40 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (6144 MB per container)
19/04/20 03:34:40 INFO Client: Will allocate AM container, with 1408 MB memory including 384 MB overhead
19/04/20 03:34:40 INFO Client: Setting up container launch context for our AM
19/04/20 03:34:40 INFO Client: Setting up the launch environment for our AM container
19/04/20 03:34:40 INFO Client: Preparing resources for our AM container
19/04/20 03:34:40 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
19/04/20 03:34:42 INFO Client: Uploading resource file:/mnt/tmp/spark-3ce6e933-d929-4a81-961b-36a29fed7ed2/__spark_libs__4120548654274231980.zip -> hdfs://ip-172-31-51-240.ec2.internal:8020/user/hadoop/.sparkStaging/application_1555731178011_0001/__spark_libs__4120548654274231980.zip
19/04/20 03:34:49 INFO Client: Uploading resource s3://cs-6240-hemnaniv/DGPP-project/v3-all-pair-5-clusters-n-7/spark-dpp-1.0.jar -> hdfs://ip-172-31-51-240.ec2.internal:8020/user/hadoop/.sparkStaging/application_1555731178011_0001/spark-dpp-1.0.jar
19/04/20 03:34:49 INFO S3NativeFileSystem: Opening 's3://cs-6240-hemnaniv/DGPP-project/v3-all-pair-5-clusters-n-7/spark-dpp-1.0.jar' for reading
19/04/20 03:34:49 INFO Client: Uploading resource file:/mnt/tmp/spark-3ce6e933-d929-4a81-961b-36a29fed7ed2/__spark_conf__2267007420743817435.zip -> hdfs://ip-172-31-51-240.ec2.internal:8020/user/hadoop/.sparkStaging/application_1555731178011_0001/__spark_conf__.zip
19/04/20 03:34:49 INFO SecurityManager: Changing view acls to: hadoop
19/04/20 03:34:49 INFO SecurityManager: Changing modify acls to: hadoop
19/04/20 03:34:49 INFO SecurityManager: Changing view acls groups to: 
19/04/20 03:34:49 INFO SecurityManager: Changing modify acls groups to: 
19/04/20 03:34:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
19/04/20 03:34:51 INFO Client: Submitting application application_1555731178011_0001 to ResourceManager
19/04/20 03:34:52 INFO YarnClientImpl: Submitted application application_1555731178011_0001
19/04/20 03:34:53 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:34:53 INFO Client: 
	 client token: N/A
	 diagnostics: [Sat Apr 20 03:34:52 +0000 2019] Scheduler has assigned a container for AM, waiting for AM container to be launched
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1555731291810
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-51-240.ec2.internal:20888/proxy/application_1555731178011_0001/
	 user: hadoop
19/04/20 03:34:54 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:34:55 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:34:56 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:34:57 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:34:58 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:34:59 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:35:00 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:35:01 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:35:02 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:35:03 INFO Client: Application report for application_1555731178011_0001 (state: ACCEPTED)
19/04/20 03:35:04 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:04 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: ip-172-31-51-252.ec2.internal
	 ApplicationMaster RPC port: 33739
	 queue: default
	 start time: 1555731291810
	 final status: UNDEFINED
	 tracking URL: http://ip-172-31-51-240.ec2.internal:20888/proxy/application_1555731178011_0001/
	 user: hadoop
19/04/20 03:35:05 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:06 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:07 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:08 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:09 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:10 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:11 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:12 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:13 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:14 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:15 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:16 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:17 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:18 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:19 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:20 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:21 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:22 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:23 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:24 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:25 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:26 INFO Client: Application report for application_1555731178011_0001 (state: RUNNING)
19/04/20 03:35:27 INFO Client: Application report for application_1555731178011_0001 (state: FINISHED)
19/04/20 03:35:27 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: ip-172-31-51-252.ec2.internal
	 ApplicationMaster RPC port: 33739
	 queue: default
	 start time: 1555731291810
	 final status: SUCCEEDED
	 tracking URL: http://ip-172-31-51-240.ec2.internal:20888/proxy/application_1555731178011_0001/
	 user: hadoop
19/04/20 03:35:27 INFO ShutdownHookManager: Shutdown hook called
19/04/20 03:35:27 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-de8b2728-10d0-4f97-b731-50f9b0e8d4d1
19/04/20 03:35:27 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-3ce6e933-d929-4a81-961b-36a29fed7ed2
Command exiting with ret '0'